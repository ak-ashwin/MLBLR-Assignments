{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4b_2 (1).ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1_1kwmwgL7g94jI6BEtcgm-D2_AFk0zxK",
          "timestamp": 1519101209834
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 20\n",
        "num_filter = 24\n",
        "compression = 0.5\n",
        "dropout_rate = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 24, dropout_rate = 0.3):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 24, dropout_rate = 0.3):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_filter = 24\n",
        "dropout_rate = 0.3\n",
        "l = 20\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 16775
        },
        "outputId": "cb92835e-73b1-446f-f086-a359e0b52ee8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526448487199,
          "user_tz": -330,
          "elapsed": 1167,
          "user": {
            "displayName": "Ddev Dev",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102531774737788455146"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 32, 32, 24)   648         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 32, 32, 24)   96          conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 32, 32, 24)   0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 32, 32, 12)   2592        activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_167 (Dropout)           (None, 32, 32, 12)   0           conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_161 (Concatenate)   (None, 32, 32, 36)   0           conv2d_169[0][0]                 \n",
            "                                                                 dropout_167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 32, 32, 36)   144         concatenate_161[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 32, 32, 36)   0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 32, 32, 12)   3888        activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_168 (Dropout)           (None, 32, 32, 12)   0           conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_162 (Concatenate)   (None, 32, 32, 48)   0           concatenate_161[0][0]            \n",
            "                                                                 dropout_168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 32, 32, 48)   192         concatenate_162[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 32, 32, 48)   0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 32, 32, 12)   5184        activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_169 (Dropout)           (None, 32, 32, 12)   0           conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_163 (Concatenate)   (None, 32, 32, 60)   0           concatenate_162[0][0]            \n",
            "                                                                 dropout_169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 32, 32, 60)   240         concatenate_163[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 32, 32, 60)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 32, 32, 12)   6480        activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_170 (Dropout)           (None, 32, 32, 12)   0           conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_164 (Concatenate)   (None, 32, 32, 72)   0           concatenate_163[0][0]            \n",
            "                                                                 dropout_170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 32, 32, 72)   288         concatenate_164[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 32, 32, 72)   0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 32, 32, 12)   7776        activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_171 (Dropout)           (None, 32, 32, 12)   0           conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_165 (Concatenate)   (None, 32, 32, 84)   0           concatenate_164[0][0]            \n",
            "                                                                 dropout_171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 32, 32, 84)   336         concatenate_165[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 32, 32, 84)   0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 32, 32, 12)   9072        activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_172 (Dropout)           (None, 32, 32, 12)   0           conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_166 (Concatenate)   (None, 32, 32, 96)   0           concatenate_165[0][0]            \n",
            "                                                                 dropout_172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 32, 32, 96)   384         concatenate_166[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 32, 32, 96)   0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 32, 32, 12)   10368       activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_173 (Dropout)           (None, 32, 32, 12)   0           conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_167 (Concatenate)   (None, 32, 32, 108)  0           concatenate_166[0][0]            \n",
            "                                                                 dropout_173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 32, 32, 108)  432         concatenate_167[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 32, 32, 108)  0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 32, 32, 12)   11664       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_174 (Dropout)           (None, 32, 32, 12)   0           conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_168 (Concatenate)   (None, 32, 32, 120)  0           concatenate_167[0][0]            \n",
            "                                                                 dropout_174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 32, 32, 120)  480         concatenate_168[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 32, 32, 120)  0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 32, 32, 12)   12960       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_175 (Dropout)           (None, 32, 32, 12)   0           conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_169 (Concatenate)   (None, 32, 32, 132)  0           concatenate_168[0][0]            \n",
            "                                                                 dropout_175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 32, 32, 132)  528         concatenate_169[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 32, 32, 132)  0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 32, 32, 12)   14256       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_176 (Dropout)           (None, 32, 32, 12)   0           conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_170 (Concatenate)   (None, 32, 32, 144)  0           concatenate_169[0][0]            \n",
            "                                                                 dropout_176[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 32, 32, 144)  576         concatenate_170[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 32, 32, 144)  0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 32, 32, 12)   15552       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_177 (Dropout)           (None, 32, 32, 12)   0           conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_171 (Concatenate)   (None, 32, 32, 156)  0           concatenate_170[0][0]            \n",
            "                                                                 dropout_177[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 32, 32, 156)  624         concatenate_171[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 32, 32, 156)  0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 32, 32, 12)   16848       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_178 (Dropout)           (None, 32, 32, 12)   0           conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_172 (Concatenate)   (None, 32, 32, 168)  0           concatenate_171[0][0]            \n",
            "                                                                 dropout_178[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 32, 32, 168)  672         concatenate_172[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 32, 32, 168)  0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 32, 32, 12)   18144       activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_179 (Dropout)           (None, 32, 32, 12)   0           conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_173 (Concatenate)   (None, 32, 32, 180)  0           concatenate_172[0][0]            \n",
            "                                                                 dropout_179[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 32, 32, 180)  720         concatenate_173[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 32, 32, 180)  0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 32, 32, 12)   19440       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_180 (Dropout)           (None, 32, 32, 12)   0           conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_174 (Concatenate)   (None, 32, 32, 192)  0           concatenate_173[0][0]            \n",
            "                                                                 dropout_180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 32, 32, 192)  768         concatenate_174[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 32, 32, 192)  0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 32, 32, 12)   20736       activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_181 (Dropout)           (None, 32, 32, 12)   0           conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_175 (Concatenate)   (None, 32, 32, 204)  0           concatenate_174[0][0]            \n",
            "                                                                 dropout_181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 32, 32, 204)  816         concatenate_175[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 32, 32, 204)  0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 32, 32, 12)   22032       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_182 (Dropout)           (None, 32, 32, 12)   0           conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_176 (Concatenate)   (None, 32, 32, 216)  0           concatenate_175[0][0]            \n",
            "                                                                 dropout_182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 32, 32, 216)  864         concatenate_176[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 32, 32, 216)  0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 32, 32, 12)   23328       activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_183 (Dropout)           (None, 32, 32, 12)   0           conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_177 (Concatenate)   (None, 32, 32, 228)  0           concatenate_176[0][0]            \n",
            "                                                                 dropout_183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 32, 32, 228)  912         concatenate_177[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 32, 32, 228)  0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 32, 32, 12)   24624       activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_184 (Dropout)           (None, 32, 32, 12)   0           conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_178 (Concatenate)   (None, 32, 32, 240)  0           concatenate_177[0][0]            \n",
            "                                                                 dropout_184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 32, 32, 240)  960         concatenate_178[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 32, 32, 240)  0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 32, 32, 12)   25920       activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_185 (Dropout)           (None, 32, 32, 12)   0           conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_179 (Concatenate)   (None, 32, 32, 252)  0           concatenate_178[0][0]            \n",
            "                                                                 dropout_185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 32, 32, 252)  1008        concatenate_179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 32, 32, 252)  0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 32, 32, 12)   27216       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_186 (Dropout)           (None, 32, 32, 12)   0           conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_180 (Concatenate)   (None, 32, 32, 264)  0           concatenate_179[0][0]            \n",
            "                                                                 dropout_186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 32, 32, 264)  1056        concatenate_180[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 32, 32, 264)  0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 32, 32, 12)   3168        activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_187 (Dropout)           (None, 32, 32, 12)   0           conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 12)   0           dropout_187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 16, 16, 12)   48          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 16, 16, 12)   0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 16, 16, 12)   1296        activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_188 (Dropout)           (None, 16, 16, 12)   0           conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_181 (Concatenate)   (None, 16, 16, 24)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 16, 16, 24)   96          concatenate_181[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 16, 16, 24)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 16, 16, 12)   2592        activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_189 (Dropout)           (None, 16, 16, 12)   0           conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_182 (Concatenate)   (None, 16, 16, 36)   0           concatenate_181[0][0]            \n",
            "                                                                 dropout_189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 16, 16, 36)   144         concatenate_182[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 16, 16, 36)   0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 16, 16, 12)   3888        activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_190 (Dropout)           (None, 16, 16, 12)   0           conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_183 (Concatenate)   (None, 16, 16, 48)   0           concatenate_182[0][0]            \n",
            "                                                                 dropout_190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 16, 16, 48)   192         concatenate_183[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 16, 16, 48)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 16, 16, 12)   5184        activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_191 (Dropout)           (None, 16, 16, 12)   0           conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_184 (Concatenate)   (None, 16, 16, 60)   0           concatenate_183[0][0]            \n",
            "                                                                 dropout_191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 16, 16, 60)   240         concatenate_184[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 16, 16, 60)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 16, 16, 12)   6480        activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_192 (Dropout)           (None, 16, 16, 12)   0           conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_185 (Concatenate)   (None, 16, 16, 72)   0           concatenate_184[0][0]            \n",
            "                                                                 dropout_192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 16, 16, 72)   288         concatenate_185[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 16, 16, 72)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 16, 16, 12)   7776        activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_193 (Dropout)           (None, 16, 16, 12)   0           conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_186 (Concatenate)   (None, 16, 16, 84)   0           concatenate_185[0][0]            \n",
            "                                                                 dropout_193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 16, 16, 84)   336         concatenate_186[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 16, 16, 84)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 16, 16, 12)   9072        activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_194 (Dropout)           (None, 16, 16, 12)   0           conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_187 (Concatenate)   (None, 16, 16, 96)   0           concatenate_186[0][0]            \n",
            "                                                                 dropout_194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 16, 16, 96)   384         concatenate_187[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 16, 16, 12)   10368       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_195 (Dropout)           (None, 16, 16, 12)   0           conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_188 (Concatenate)   (None, 16, 16, 108)  0           concatenate_187[0][0]            \n",
            "                                                                 dropout_195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 16, 16, 108)  432         concatenate_188[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 16, 16, 108)  0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 16, 16, 12)   11664       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_196 (Dropout)           (None, 16, 16, 12)   0           conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_189 (Concatenate)   (None, 16, 16, 120)  0           concatenate_188[0][0]            \n",
            "                                                                 dropout_196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 16, 16, 120)  480         concatenate_189[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 16, 16, 120)  0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 16, 16, 12)   12960       activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_197 (Dropout)           (None, 16, 16, 12)   0           conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_190 (Concatenate)   (None, 16, 16, 132)  0           concatenate_189[0][0]            \n",
            "                                                                 dropout_197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 16, 16, 132)  528         concatenate_190[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 16, 16, 132)  0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 16, 16, 12)   14256       activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_198 (Dropout)           (None, 16, 16, 12)   0           conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_191 (Concatenate)   (None, 16, 16, 144)  0           concatenate_190[0][0]            \n",
            "                                                                 dropout_198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 16, 16, 144)  576         concatenate_191[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 16, 16, 144)  0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 16, 16, 12)   15552       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_199 (Dropout)           (None, 16, 16, 12)   0           conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_192 (Concatenate)   (None, 16, 16, 156)  0           concatenate_191[0][0]            \n",
            "                                                                 dropout_199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 16, 16, 156)  624         concatenate_192[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 16, 16, 156)  0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 16, 16, 12)   16848       activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_200 (Dropout)           (None, 16, 16, 12)   0           conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_193 (Concatenate)   (None, 16, 16, 168)  0           concatenate_192[0][0]            \n",
            "                                                                 dropout_200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 16, 16, 168)  672         concatenate_193[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 16, 16, 168)  0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 16, 16, 12)   18144       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_201 (Dropout)           (None, 16, 16, 12)   0           conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_194 (Concatenate)   (None, 16, 16, 180)  0           concatenate_193[0][0]            \n",
            "                                                                 dropout_201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 16, 16, 180)  720         concatenate_194[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 16, 16, 180)  0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 16, 16, 12)   19440       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_202 (Dropout)           (None, 16, 16, 12)   0           conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_195 (Concatenate)   (None, 16, 16, 192)  0           concatenate_194[0][0]            \n",
            "                                                                 dropout_202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 16, 16, 192)  768         concatenate_195[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 16, 16, 192)  0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 16, 16, 12)   20736       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_203 (Dropout)           (None, 16, 16, 12)   0           conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_196 (Concatenate)   (None, 16, 16, 204)  0           concatenate_195[0][0]            \n",
            "                                                                 dropout_203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 16, 16, 204)  816         concatenate_196[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 16, 16, 204)  0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 16, 16, 12)   22032       activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_204 (Dropout)           (None, 16, 16, 12)   0           conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_197 (Concatenate)   (None, 16, 16, 216)  0           concatenate_196[0][0]            \n",
            "                                                                 dropout_204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 16, 16, 216)  864         concatenate_197[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 16, 16, 216)  0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 16, 16, 12)   23328       activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_205 (Dropout)           (None, 16, 16, 12)   0           conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_198 (Concatenate)   (None, 16, 16, 228)  0           concatenate_197[0][0]            \n",
            "                                                                 dropout_205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 16, 16, 228)  912         concatenate_198[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 16, 16, 228)  0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 16, 16, 12)   24624       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_206 (Dropout)           (None, 16, 16, 12)   0           conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_199 (Concatenate)   (None, 16, 16, 240)  0           concatenate_198[0][0]            \n",
            "                                                                 dropout_206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 16, 16, 240)  960         concatenate_199[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 16, 16, 240)  0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 16, 16, 12)   25920       activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_207 (Dropout)           (None, 16, 16, 12)   0           conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_200 (Concatenate)   (None, 16, 16, 252)  0           concatenate_199[0][0]            \n",
            "                                                                 dropout_207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 16, 16, 252)  1008        concatenate_200[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 16, 16, 252)  0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 16, 16, 12)   3024        activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_208 (Dropout)           (None, 16, 16, 12)   0           conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 12)     0           dropout_208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 8, 8, 12)     48          average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 8, 8, 12)     0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 8, 8, 12)     1296        activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_209 (Dropout)           (None, 8, 8, 12)     0           conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_201 (Concatenate)   (None, 8, 8, 24)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 8, 8, 24)     96          concatenate_201[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 8, 8, 24)     0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 8, 8, 12)     2592        activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_210 (Dropout)           (None, 8, 8, 12)     0           conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_202 (Concatenate)   (None, 8, 8, 36)     0           concatenate_201[0][0]            \n",
            "                                                                 dropout_210[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 8, 8, 36)     144         concatenate_202[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 8, 8, 36)     0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 8, 8, 12)     3888        activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_211 (Dropout)           (None, 8, 8, 12)     0           conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_203 (Concatenate)   (None, 8, 8, 48)     0           concatenate_202[0][0]            \n",
            "                                                                 dropout_211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 8, 8, 48)     192         concatenate_203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 8, 8, 48)     0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 8, 8, 12)     5184        activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_212 (Dropout)           (None, 8, 8, 12)     0           conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_204 (Concatenate)   (None, 8, 8, 60)     0           concatenate_203[0][0]            \n",
            "                                                                 dropout_212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 8, 8, 60)     240         concatenate_204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 8, 8, 60)     0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 8, 8, 12)     6480        activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_213 (Dropout)           (None, 8, 8, 12)     0           conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_205 (Concatenate)   (None, 8, 8, 72)     0           concatenate_204[0][0]            \n",
            "                                                                 dropout_213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 8, 8, 72)     288         concatenate_205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 8, 8, 72)     0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 8, 8, 12)     7776        activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_214 (Dropout)           (None, 8, 8, 12)     0           conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_206 (Concatenate)   (None, 8, 8, 84)     0           concatenate_205[0][0]            \n",
            "                                                                 dropout_214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 8, 8, 84)     336         concatenate_206[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 8, 8, 84)     0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 8, 8, 12)     9072        activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_215 (Dropout)           (None, 8, 8, 12)     0           conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_207 (Concatenate)   (None, 8, 8, 96)     0           concatenate_206[0][0]            \n",
            "                                                                 dropout_215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 8, 8, 96)     384         concatenate_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 8, 8, 96)     0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 8, 8, 12)     10368       activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_216 (Dropout)           (None, 8, 8, 12)     0           conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_208 (Concatenate)   (None, 8, 8, 108)    0           concatenate_207[0][0]            \n",
            "                                                                 dropout_216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 8, 8, 108)    432         concatenate_208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 8, 8, 108)    0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 8, 8, 12)     11664       activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_217 (Dropout)           (None, 8, 8, 12)     0           conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_209 (Concatenate)   (None, 8, 8, 120)    0           concatenate_208[0][0]            \n",
            "                                                                 dropout_217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 8, 8, 120)    480         concatenate_209[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 8, 8, 120)    0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 8, 8, 12)     12960       activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_218 (Dropout)           (None, 8, 8, 12)     0           conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_210 (Concatenate)   (None, 8, 8, 132)    0           concatenate_209[0][0]            \n",
            "                                                                 dropout_218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 8, 8, 132)    528         concatenate_210[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 8, 8, 132)    0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 8, 8, 12)     14256       activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_219 (Dropout)           (None, 8, 8, 12)     0           conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_211 (Concatenate)   (None, 8, 8, 144)    0           concatenate_210[0][0]            \n",
            "                                                                 dropout_219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 8, 8, 144)    576         concatenate_211[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 8, 8, 144)    0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 8, 8, 12)     15552       activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_220 (Dropout)           (None, 8, 8, 12)     0           conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_212 (Concatenate)   (None, 8, 8, 156)    0           concatenate_211[0][0]            \n",
            "                                                                 dropout_220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 8, 8, 156)    624         concatenate_212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 8, 8, 156)    0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 8, 8, 12)     16848       activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_221 (Dropout)           (None, 8, 8, 12)     0           conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_213 (Concatenate)   (None, 8, 8, 168)    0           concatenate_212[0][0]            \n",
            "                                                                 dropout_221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 8, 8, 168)    672         concatenate_213[0][0]            \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 8, 8, 168)    0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 8, 8, 12)     18144       activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_222 (Dropout)           (None, 8, 8, 12)     0           conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_214 (Concatenate)   (None, 8, 8, 180)    0           concatenate_213[0][0]            \n",
            "                                                                 dropout_222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 8, 8, 180)    720         concatenate_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 8, 8, 180)    0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 8, 8, 12)     19440       activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_223 (Dropout)           (None, 8, 8, 12)     0           conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_215 (Concatenate)   (None, 8, 8, 192)    0           concatenate_214[0][0]            \n",
            "                                                                 dropout_223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 8, 8, 192)    768         concatenate_215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 8, 8, 192)    0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 8, 8, 12)     20736       activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_224 (Dropout)           (None, 8, 8, 12)     0           conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_216 (Concatenate)   (None, 8, 8, 204)    0           concatenate_215[0][0]            \n",
            "                                                                 dropout_224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 8, 8, 204)    816         concatenate_216[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 8, 8, 204)    0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 8, 8, 12)     22032       activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_225 (Dropout)           (None, 8, 8, 12)     0           conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_217 (Concatenate)   (None, 8, 8, 216)    0           concatenate_216[0][0]            \n",
            "                                                                 dropout_225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 8, 8, 216)    864         concatenate_217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 8, 8, 216)    0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 8, 8, 12)     23328       activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_226 (Dropout)           (None, 8, 8, 12)     0           conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_218 (Concatenate)   (None, 8, 8, 228)    0           concatenate_217[0][0]            \n",
            "                                                                 dropout_226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 8, 8, 228)    912         concatenate_218[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 8, 8, 228)    0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 8, 8, 12)     24624       activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_227 (Dropout)           (None, 8, 8, 12)     0           conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_219 (Concatenate)   (None, 8, 8, 240)    0           concatenate_218[0][0]            \n",
            "                                                                 dropout_227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 8, 8, 240)    960         concatenate_219[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 8, 8, 240)    0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 8, 8, 12)     25920       activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_228 (Dropout)           (None, 8, 8, 12)     0           conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_220 (Concatenate)   (None, 8, 8, 252)    0           concatenate_219[0][0]            \n",
            "                                                                 dropout_228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 8, 8, 252)    1008        concatenate_220[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 8, 8, 252)    0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 8, 8, 12)     3024        activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_229 (Dropout)           (None, 8, 8, 12)     0           conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 4, 4, 12)     0           dropout_229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 4, 4, 12)     48          average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 4, 4, 12)     0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 4, 4, 12)     1296        activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_230 (Dropout)           (None, 4, 4, 12)     0           conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_221 (Concatenate)   (None, 4, 4, 24)     0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 4, 4, 24)     96          concatenate_221[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 4, 4, 24)     0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 4, 4, 12)     2592        activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_231 (Dropout)           (None, 4, 4, 12)     0           conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_222 (Concatenate)   (None, 4, 4, 36)     0           concatenate_221[0][0]            \n",
            "                                                                 dropout_231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 4, 4, 36)     144         concatenate_222[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 4, 4, 36)     0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 4, 4, 12)     3888        activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_232 (Dropout)           (None, 4, 4, 12)     0           conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_223 (Concatenate)   (None, 4, 4, 48)     0           concatenate_222[0][0]            \n",
            "                                                                 dropout_232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 4, 4, 48)     192         concatenate_223[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 4, 4, 48)     0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 4, 4, 12)     5184        activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_233 (Dropout)           (None, 4, 4, 12)     0           conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_224 (Concatenate)   (None, 4, 4, 60)     0           concatenate_223[0][0]            \n",
            "                                                                 dropout_233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 4, 4, 60)     240         concatenate_224[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 4, 4, 60)     0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 4, 4, 12)     6480        activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_234 (Dropout)           (None, 4, 4, 12)     0           conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_225 (Concatenate)   (None, 4, 4, 72)     0           concatenate_224[0][0]            \n",
            "                                                                 dropout_234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 4, 4, 72)     288         concatenate_225[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 4, 4, 72)     0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 4, 4, 12)     7776        activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_235 (Dropout)           (None, 4, 4, 12)     0           conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_226 (Concatenate)   (None, 4, 4, 84)     0           concatenate_225[0][0]            \n",
            "                                                                 dropout_235[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 4, 4, 84)     336         concatenate_226[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 4, 4, 84)     0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 4, 4, 12)     9072        activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_236 (Dropout)           (None, 4, 4, 12)     0           conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_227 (Concatenate)   (None, 4, 4, 96)     0           concatenate_226[0][0]            \n",
            "                                                                 dropout_236[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 4, 4, 96)     384         concatenate_227[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 4, 4, 96)     0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 4, 4, 12)     10368       activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_237 (Dropout)           (None, 4, 4, 12)     0           conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_228 (Concatenate)   (None, 4, 4, 108)    0           concatenate_227[0][0]            \n",
            "                                                                 dropout_237[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 4, 4, 108)    432         concatenate_228[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 4, 4, 108)    0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 4, 4, 12)     11664       activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_238 (Dropout)           (None, 4, 4, 12)     0           conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_229 (Concatenate)   (None, 4, 4, 120)    0           concatenate_228[0][0]            \n",
            "                                                                 dropout_238[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 4, 4, 120)    480         concatenate_229[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 4, 4, 120)    0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 4, 4, 12)     12960       activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_239 (Dropout)           (None, 4, 4, 12)     0           conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_230 (Concatenate)   (None, 4, 4, 132)    0           concatenate_229[0][0]            \n",
            "                                                                 dropout_239[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 4, 4, 132)    528         concatenate_230[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 4, 4, 132)    0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 4, 4, 12)     14256       activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_240 (Dropout)           (None, 4, 4, 12)     0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_231 (Concatenate)   (None, 4, 4, 144)    0           concatenate_230[0][0]            \n",
            "                                                                 dropout_240[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 4, 4, 144)    576         concatenate_231[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 4, 4, 144)    0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 4, 4, 12)     15552       activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_241 (Dropout)           (None, 4, 4, 12)     0           conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_232 (Concatenate)   (None, 4, 4, 156)    0           concatenate_231[0][0]            \n",
            "                                                                 dropout_241[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 4, 4, 156)    624         concatenate_232[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 4, 4, 156)    0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 4, 4, 12)     16848       activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_242 (Dropout)           (None, 4, 4, 12)     0           conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_233 (Concatenate)   (None, 4, 4, 168)    0           concatenate_232[0][0]            \n",
            "                                                                 dropout_242[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 4, 4, 168)    672         concatenate_233[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 4, 4, 168)    0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 4, 4, 12)     18144       activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_243 (Dropout)           (None, 4, 4, 12)     0           conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_234 (Concatenate)   (None, 4, 4, 180)    0           concatenate_233[0][0]            \n",
            "                                                                 dropout_243[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 4, 4, 180)    720         concatenate_234[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 4, 4, 180)    0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 4, 4, 12)     19440       activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_244 (Dropout)           (None, 4, 4, 12)     0           conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_235 (Concatenate)   (None, 4, 4, 192)    0           concatenate_234[0][0]            \n",
            "                                                                 dropout_244[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 4, 4, 192)    768         concatenate_235[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 4, 4, 192)    0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 4, 4, 12)     20736       activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_245 (Dropout)           (None, 4, 4, 12)     0           conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_236 (Concatenate)   (None, 4, 4, 204)    0           concatenate_235[0][0]            \n",
            "                                                                 dropout_245[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 4, 4, 204)    816         concatenate_236[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 4, 4, 204)    0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 4, 4, 12)     22032       activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_246 (Dropout)           (None, 4, 4, 12)     0           conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_237 (Concatenate)   (None, 4, 4, 216)    0           concatenate_236[0][0]            \n",
            "                                                                 dropout_246[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 4, 4, 216)    864         concatenate_237[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 4, 4, 216)    0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 4, 4, 12)     23328       activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_247 (Dropout)           (None, 4, 4, 12)     0           conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_238 (Concatenate)   (None, 4, 4, 228)    0           concatenate_237[0][0]            \n",
            "                                                                 dropout_247[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 4, 4, 228)    912         concatenate_238[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 4, 4, 228)    0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 4, 4, 12)     24624       activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_248 (Dropout)           (None, 4, 4, 12)     0           conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_239 (Concatenate)   (None, 4, 4, 240)    0           concatenate_238[0][0]            \n",
            "                                                                 dropout_248[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 4, 4, 240)    960         concatenate_239[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 4, 4, 240)    0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 4, 4, 12)     25920       activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_249 (Dropout)           (None, 4, 4, 12)     0           conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_240 (Concatenate)   (None, 4, 4, 252)    0           concatenate_239[0][0]            \n",
            "                                                                 dropout_249[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 4, 4, 252)    1008        concatenate_240[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 4, 4, 252)    0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 2, 2, 252)    0           activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 1008)         0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           10090       flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,179,874\n",
            "Trainable params: 1,157,194\n",
            "Non-trainable params: 22,680\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EI27GPhwVtQT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "path=\"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3673
        },
        "outputId": "adbc258e-fb5b-4dcf-edcd-495aa4d78282",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526478171816,
          "user_tz": -330,
          "elapsed": 26514602,
          "user": {
            "displayName": "Ddev Dev",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102531774737788455146"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "          callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 556s 11ms/step - loss: 0.8280 - acc: 0.7075 - val_loss: 1.2558 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.64380, saving model to weights.hdf5\n",
            "Epoch 2/50\n",
            "14720/50000 [=======>......................] - ETA: 5:49 - loss: 0.7768 - acc: 0.7221"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.7605 - acc: 0.7304 - val_loss: 1.5378 - val_acc: 0.6245\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.64380\n",
            "Epoch 3/50\n",
            "35456/50000 [====================>.........] - ETA: 2:23 - loss: 0.7099 - acc: 0.7520"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.7084 - acc: 0.7520 - val_loss: 1.1243 - val_acc: 0.7053\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.64380 to 0.70530, saving model to weights.hdf5\n",
            "Epoch 4/50\n",
            "37120/50000 [=====================>........] - ETA: 2:07 - loss: 0.6720 - acc: 0.7633"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.6652 - acc: 0.7659 - val_loss: 1.6416 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.70530\n",
            "Epoch 5/50\n",
            "42368/50000 [========================>.....] - ETA: 1:15 - loss: 0.6304 - acc: 0.7798"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.6276 - acc: 0.7809 - val_loss: 1.4591 - val_acc: 0.6493\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.70530\n",
            "Epoch 6/50\n",
            "44032/50000 [=========================>....] - ETA: 59s - loss: 0.5965 - acc: 0.7905 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.5982 - acc: 0.7903 - val_loss: 1.0515 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.70530 to 0.70640, saving model to weights.hdf5\n",
            "Epoch 7/50\n",
            "39552/50000 [======================>.......] - ETA: 1:43 - loss: 0.5730 - acc: 0.7987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.5712 - acc: 0.7995 - val_loss: 1.4408 - val_acc: 0.6534\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.70640\n",
            "Epoch 8/50\n",
            "43136/50000 [========================>.....] - ETA: 1:08 - loss: 0.5458 - acc: 0.8073"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.5465 - acc: 0.8068 - val_loss: 1.2033 - val_acc: 0.6972\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.70640\n",
            "Epoch 9/50\n",
            "44160/50000 [=========================>....] - ETA: 57s - loss: 0.5204 - acc: 0.8209"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.5221 - acc: 0.8189 - val_loss: 1.4279 - val_acc: 0.6545\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.70640\n",
            "Epoch 10/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.5077 - acc: 0.8222"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.5066 - acc: 0.8228 - val_loss: 0.8823 - val_acc: 0.7622\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.70640 to 0.76220, saving model to weights.hdf5\n",
            "Epoch 11/50\n",
            "39424/50000 [======================>.......] - ETA: 1:44 - loss: 0.4849 - acc: 0.8316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.4859 - acc: 0.8313 - val_loss: 1.1774 - val_acc: 0.7021\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.76220\n",
            "Epoch 12/50\n",
            "42880/50000 [========================>.....] - ETA: 1:10 - loss: 0.4662 - acc: 0.8375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.4685 - acc: 0.8362 - val_loss: 1.3629 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.76220\n",
            "Epoch 13/50\n",
            "44032/50000 [=========================>....] - ETA: 59s - loss: 0.4543 - acc: 0.8409 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.4546 - acc: 0.8408 - val_loss: 0.9634 - val_acc: 0.7278\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.76220\n",
            "Epoch 14/50\n",
            "44288/50000 [=========================>....] - ETA: 56s - loss: 0.4357 - acc: 0.8498"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.4348 - acc: 0.8507 - val_loss: 1.3349 - val_acc: 0.6814\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.76220\n",
            "Epoch 15/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.4269 - acc: 0.8511"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.4270 - acc: 0.8514 - val_loss: 0.8514 - val_acc: 0.7795\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.76220 to 0.77950, saving model to weights.hdf5\n",
            "Epoch 16/50\n",
            "39424/50000 [======================>.......] - ETA: 1:44 - loss: 0.4079 - acc: 0.8573"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.4110 - acc: 0.8569 - val_loss: 0.9223 - val_acc: 0.7574\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.77950\n",
            "Epoch 17/50\n",
            "42880/50000 [========================>.....] - ETA: 1:10 - loss: 0.4010 - acc: 0.8596"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 531s 11ms/step - loss: 0.3991 - acc: 0.8604 - val_loss: 1.2191 - val_acc: 0.7348\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.77950\n",
            "Epoch 18/50\n",
            "44032/50000 [=========================>....] - ETA: 59s - loss: 0.3916 - acc: 0.8629 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.3929 - acc: 0.8625 - val_loss: 1.8483 - val_acc: 0.6196\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.77950\n",
            "Epoch 19/50\n",
            "44288/50000 [=========================>....] - ETA: 56s - loss: 0.3801 - acc: 0.8656"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.3811 - acc: 0.8658 - val_loss: 0.7203 - val_acc: 0.8082\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.77950 to 0.80820, saving model to weights.hdf5\n",
            "Epoch 20/50\n",
            "39424/50000 [======================>.......] - ETA: 1:44 - loss: 0.3684 - acc: 0.8692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.3719 - acc: 0.8688 - val_loss: 1.1176 - val_acc: 0.7315\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80820\n",
            "Epoch 21/50\n",
            "42880/50000 [========================>.....] - ETA: 1:10 - loss: 0.3602 - acc: 0.8758"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.3614 - acc: 0.8750 - val_loss: 1.2486 - val_acc: 0.7181\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80820\n",
            "Epoch 22/50\n",
            "44032/50000 [=========================>....] - ETA: 59s - loss: 0.3509 - acc: 0.8764 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.3527 - acc: 0.8758 - val_loss: 0.9031 - val_acc: 0.7749\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80820\n",
            "Epoch 23/50\n",
            "44288/50000 [=========================>....] - ETA: 56s - loss: 0.3396 - acc: 0.8813"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.3417 - acc: 0.8805 - val_loss: 0.9148 - val_acc: 0.7785\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80820\n",
            "Epoch 24/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.3401 - acc: 0.8816"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.3392 - acc: 0.8822 - val_loss: 1.0542 - val_acc: 0.7564\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80820\n",
            "Epoch 25/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.3269 - acc: 0.8859"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 530s 11ms/step - loss: 0.3269 - acc: 0.8861 - val_loss: 1.0506 - val_acc: 0.7627\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80820\n",
            "Epoch 26/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.3144 - acc: 0.8907"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.3185 - acc: 0.8891 - val_loss: 1.3841 - val_acc: 0.7194\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80820\n",
            "Epoch 27/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.3101 - acc: 0.8907"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.3115 - acc: 0.8903 - val_loss: 0.8026 - val_acc: 0.7997\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80820\n",
            "Epoch 28/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.3065 - acc: 0.8913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.3039 - acc: 0.8923 - val_loss: 0.9551 - val_acc: 0.7814\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80820\n",
            "Epoch 29/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.3046 - acc: 0.8933"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.3053 - acc: 0.8928 - val_loss: 0.9527 - val_acc: 0.7715\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80820\n",
            "Epoch 30/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.2926 - acc: 0.8969"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2945 - acc: 0.8968 - val_loss: 0.9296 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80820\n",
            "Epoch 31/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.2856 - acc: 0.8998"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2889 - acc: 0.8992 - val_loss: 0.9737 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80820\n",
            "Epoch 32/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.2791 - acc: 0.9012"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.2817 - acc: 0.9005 - val_loss: 1.1560 - val_acc: 0.7401\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80820\n",
            "Epoch 33/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.2763 - acc: 0.9031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2777 - acc: 0.9026 - val_loss: 0.7698 - val_acc: 0.8085\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.80820 to 0.80850, saving model to weights.hdf5\n",
            "Epoch 34/50\n",
            "39424/50000 [======================>.......] - ETA: 1:44 - loss: 0.2672 - acc: 0.9060"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2697 - acc: 0.9062 - val_loss: 0.7538 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.80850 to 0.81930, saving model to weights.hdf5\n",
            "Epoch 35/50\n",
            "38144/50000 [=====================>........] - ETA: 1:57 - loss: 0.2600 - acc: 0.9083"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2614 - acc: 0.9086 - val_loss: 0.7314 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.81930\n",
            "Epoch 36/50\n",
            "42496/50000 [========================>.....] - ETA: 1:14 - loss: 0.2637 - acc: 0.9062"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2627 - acc: 0.9068 - val_loss: 1.7551 - val_acc: 0.6613\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.81930\n",
            "Epoch 37/50\n",
            "43904/50000 [=========================>....] - ETA: 1:00 - loss: 0.2497 - acc: 0.9125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2507 - acc: 0.9120 - val_loss: 0.9015 - val_acc: 0.7979\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.81930\n",
            "Epoch 38/50\n",
            "44288/50000 [=========================>....] - ETA: 56s - loss: 0.2452 - acc: 0.9140"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2470 - acc: 0.9137 - val_loss: 0.6133 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.81930 to 0.84640, saving model to weights.hdf5\n",
            "Epoch 39/50\n",
            "39424/50000 [======================>.......] - ETA: 1:44 - loss: 0.2415 - acc: 0.9142"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2426 - acc: 0.9139 - val_loss: 0.8745 - val_acc: 0.8019\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.84640\n",
            "Epoch 40/50\n",
            "42880/50000 [========================>.....] - ETA: 1:10 - loss: 0.2457 - acc: 0.9136"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2431 - acc: 0.9142 - val_loss: 0.5876 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.84640 to 0.85390, saving model to weights.hdf5\n",
            "Epoch 41/50\n",
            "39040/50000 [======================>.......] - ETA: 1:48 - loss: 0.2319 - acc: 0.9171"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.2332 - acc: 0.9165 - val_loss: 0.8706 - val_acc: 0.8062\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.85390\n",
            "Epoch 42/50\n",
            "42752/50000 [========================>.....] - ETA: 1:11 - loss: 0.2277 - acc: 0.9196"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2310 - acc: 0.9182 - val_loss: 0.9556 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.85390\n",
            "Epoch 43/50\n",
            "43904/50000 [=========================>....] - ETA: 1:00 - loss: 0.2244 - acc: 0.9204"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2258 - acc: 0.9201 - val_loss: 0.8531 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.85390\n",
            "Epoch 44/50\n",
            "44288/50000 [=========================>....] - ETA: 56s - loss: 0.2245 - acc: 0.9199"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.2232 - acc: 0.9203 - val_loss: 0.7590 - val_acc: 0.8186\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.85390\n",
            "Epoch 45/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.2173 - acc: 0.9231"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.2165 - acc: 0.9237 - val_loss: 0.8343 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.85390\n",
            "Epoch 46/50\n",
            "44416/50000 [=========================>....] - ETA: 55s - loss: 0.2153 - acc: 0.9232"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 527s 11ms/step - loss: 0.2166 - acc: 0.9228 - val_loss: 0.5934 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.85390\n",
            "Epoch 47/50\n",
            "44416/50000 [=========================>....] - ETA: 54s - loss: 0.2126 - acc: 0.9249"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 526s 11ms/step - loss: 0.2133 - acc: 0.9247 - val_loss: 0.5656 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.85390 to 0.86060, saving model to weights.hdf5\n",
            "Epoch 48/50\n",
            "39424/50000 [======================>.......] - ETA: 1:44 - loss: 0.2062 - acc: 0.9267"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 528s 11ms/step - loss: 0.2086 - acc: 0.9258 - val_loss: 0.7451 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.86060\n",
            "Epoch 49/50\n",
            "42880/50000 [========================>.....] - ETA: 1:10 - loss: 0.2087 - acc: 0.9253"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2086 - acc: 0.9258 - val_loss: 0.6913 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.86060\n",
            "Epoch 50/50\n",
            "44032/50000 [=========================>....] - ETA: 58s - loss: 0.2014 - acc: 0.9284 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 529s 11ms/step - loss: 0.2004 - acc: 0.9287 - val_loss: 0.8540 - val_acc: 0.8158\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.86060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed9cead6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "lF3wRdPDVtQc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(\"weights.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2798259e-68fd-4a8d-acdc-2135c4ee4593",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526478416123,
          "user_tz": -330,
          "elapsed": 46383,
          "user": {
            "displayName": "Ddev Dev",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102531774737788455146"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 46s 5ms/step\n",
            "Test loss: 0.5656300925970078\n",
            "Test accuracy: 0.8606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2b7e0ab-3a30-4f17-9817-45e3c072c070",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526478432089,
          "user_tz": -330,
          "elapsed": 1275,
          "user": {
            "displayName": "Ddev Dev",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102531774737788455146"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}